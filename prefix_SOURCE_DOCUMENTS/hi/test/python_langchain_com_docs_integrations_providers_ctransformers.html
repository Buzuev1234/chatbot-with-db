
    <!DOCTYPE html>
    <html>
    <head>
    <title>C Transformers | ü¶úÔ∏èüîó Langchain</title>
    </head>
    <body>
    <p>C Transformers | ü¶úÔ∏èüîó Langchain Skip to main contentIntegrationsCallbacksChat modelsDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgent toolkitsToolsVector storesGrouped by providerWandB TracingAI21 LabsAimAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasDBAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBananaBasetenBeamBedrockBiliBiliBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLCnosDBCohereCollege ConfidentialCometConfluenceC TransformersDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeep LakeDiffbotDiscordDocugamiDuckDBElasticsearchEverNoteFacebook ChatFigmaFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaLanceDBLangChain Decorators ‚ú®Llama.cppMarqoMediaWikiDumpMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMotherduckMyScaleNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeTairTelegramTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredVectaraVespaWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerC TransformersOn this pageC TransformersThis page covers how to use the C Transformers library within LangChain. It is broken into two parts: installation and setup, and then references to specific C Transformers wrappers.Installation and Setup‚ÄãInstall the Python package with pip install ctransformersDownload a supported GGML model (see Supported Models)Wrappers‚ÄãLLM‚ÄãThere exists a CTransformers LLM wrapper, which you can access with:from langchain.llms import CTransformersAPI Reference:CTransformers from langchain.llmsIt provides a unified interface for all models:llm = CTransformers(model='/path/to/ggml-gpt-2.bin', model_type='gpt2')print(llm('AI is going to'))If you are getting illegal instruction error, try using lib='avx' or lib='basic':llm = CTransformers(model='/path/to/ggml-gpt-2.bin', model_type='gpt2', lib='avx')It can be used with models hosted on the Hugging Face Hub:llm = CTransformers(model='marella/gpt-2-ggml')If a model repo has multiple model files (.bin files), specify a model file using:llm = CTransformers(model='marella/gpt-2-ggml', model_file='ggml-model.bin')Additional parameters can be passed using the config parameter:config = {'max_new_tokens': 256, 'repetition_penalty': 1.1}llm = CTransformers(model='marella/gpt-2-ggml', config=config)See Documentation for a list of available parameters.For a more detailed walkthrough of this, see this notebook.PreviousConfluenceNextDatabricksInstallation and SetupWrappersLLM</p>
    </body>
    </html>
    